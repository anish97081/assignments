{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1.  Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where\n",
        "multiprocessing is a better choice.\n",
        "\n",
        "**Scenarios Favoring Multithreading:**\n",
        "\n",
        "**1. I/O-Bound Tasks:**\n",
        "\n",
        "When tasks involve significant I/O operations (like file reading/writing, network requests, or database queries), multithreading can be beneficial. Threads can efficiently wait for I/O operations to complete without blocking the entire program, allowing other threads to run during this time.\n",
        "\n",
        "**2. Shared Memory Access:**\n",
        "\n",
        "If the tasks need to frequently share data or state, multithreading allows easier communication and data sharing since threads within the same process share memory space. This reduces the overhead of inter-process communication.\n",
        "\n",
        "**3. Low Overhead:**\n",
        "\n",
        "Creating and managing threads typically has lower overhead compared to processes. For lightweight tasks, the performance cost of switching contexts between threads is usually less than that of processes.\n",
        "\n",
        "**4. Real-Time Processing:**\n",
        "\n",
        "In scenarios requiring real-time performance (like certain game engines), threads can be prioritized, allowing for more predictable execution.\n",
        "\n",
        "**Scenarios Favoring Multiprocessing:**\n",
        "\n",
        "**1. CPU-Bound Tasks:**\n",
        "\n",
        "For tasks that require intense CPU computations (like numerical calculations, data processing, etc.), multiprocessing can be more efficient. Each process can run on a separate CPU core, taking full advantage of multi-core systems.\n",
        "\n",
        "**2. Isolation:**\n",
        "\n",
        "Multiprocessing provides better isolation. Crashes or memory leaks in one process do not affect others, which is critical for applications that require high reliability.\n",
        "\n",
        "**3. Avoiding Global Interpreter Lock (GIL):**\n",
        "\n",
        "In languages like Python, the GIL can hinder performance in multi-threaded CPU-bound programs. Multiprocessing circumvents this limitation by utilizing separate memory spaces.\n",
        "\n",
        "**4. Resource Limits:**\n",
        "\n",
        "If the tasks are resource-intensive and could exceed the memory or CPU limits of a single process, multiprocessing can manage resources more effectively by distributing the workload across multiple processes.\n",
        "\n",
        "**5. Heavy Parallel Computation:**\n",
        "\n",
        "For tasks that can be easily divided into independent sub-tasks (like batch processing or scientific simulations), multiprocessing can significantly speed up execution through parallel computation."
      ],
      "metadata": {
        "id": "ABecuvJJgRRz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Describe what a process pool is and how it helps in managing multiple processes efficiently.**\n",
        "\n",
        "A **process pool** is a collection of pre-initialized worker processes that can be used to execute tasks concurrently. This approach is especially beneficial for managing multiple processes efficiently in scenarios where creating and destroying processes for every task would be resource-intensive and time-consuming.\n",
        "\n",
        "**Benefits of Using a Process Pool:**\n",
        "\n",
        "**Performance Improvement:**\n",
        "\n",
        "By reusing processes, you reduce the overhead associated with process creation, leading to faster execution of tasks.\n",
        "\n",
        "**Scalability:**\n",
        "\n",
        "A process pool can easily scale to handle varying loads by adjusting the number of worker processes based on the current demand.\n",
        "\n",
        "**Error Handling:**\n",
        "\n",
        "Since processes are managed within a pool, handling errors and managing the lifecycle of tasks can be more straightforward. If a worker fails, it can be replaced without impacting the entire system.\n",
        "\n",
        "**Flexibility:**\n",
        "\n",
        "Process pools can often be configured for different task types, priorities, and resource limits, making them versatile for various applications."
      ],
      "metadata": {
        "id": "mjLZULMUiyrG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Explain what multiprocessing is and why it is used in Python programs.**\n",
        "\n",
        "**Multiprocessing** is a programming technique that allows the simultaneous execution of multiple processes. In Python, this is particularly valuable for optimizing the performance of CPU-bound tasks, where computations can be executed in parallel on multiple CPU cores.\n",
        "\n",
        "**Why Use Multiprocessing in Python?**\n",
        "\n",
        "**CPU-Bound Tasks:**\n",
        "\n",
        "Multiprocessing is particularly beneficial for CPU-bound tasks—those that require significant CPU time for computation (e.g., mathematical calculations, data processing). By distributing these tasks across multiple processes, you can significantly speed up execution.\n",
        "\n",
        "**Bypassing the GIL:**\n",
        "\n",
        "The Global Interpreter Lock (GIL) in CPython prevents multiple native threads from executing Python bytecodes simultaneously. Multiprocessing allows Python to bypass the GIL, enabling true parallelism and better utilization of multi-core processors.\n",
        "\n",
        "**Improved Performance:**\n",
        "\n",
        "For tasks that can be parallelized, using multiple processes can lead to substantial performance gains compared to single-threaded execution. This is especially evident in tasks involving large datasets or computationally intensive algorithms.\n",
        "\n",
        "**Resource Management:**\n",
        "\n",
        "Multiprocessing can help manage resources better in cases where tasks are independent and can be run in isolation. This is particularly useful for batch processing or parallel computations that can run without needing to share state.\n",
        "\n",
        "**Easy to Use:**\n",
        "\n",
        "The multiprocessing module provides a straightforward API for creating and managing processes, making it relatively easy to implement parallelism without delving into complex threading or low-level process management"
      ],
      "metadata": {
        "id": "1vmjElWulcur"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Write a Python program using multithreading where one thread adds numbers to a list, and another thread removes numbers from the list. Implement a mechanism to avoid race conditions using threading.Lock**"
      ],
      "metadata": {
        "id": "oY_IBzi7obLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "import random\n",
        "\n",
        "# Shared list and lock\n",
        "shared_list = []\n",
        "lock = threading.Lock()\n",
        "\n",
        "def add_numbers():\n",
        "    for i in range(10):\n",
        "        time.sleep(random.uniform(0.1, 0.5))  # Simulate work being done\n",
        "        with lock:  # Acquire the lock before modifying the list\n",
        "            shared_list.append(i)\n",
        "            print(f\"Added: {i}. Current List: {shared_list}\")\n",
        "\n",
        "def remove_numbers():\n",
        "    for _ in range(10):\n",
        "        time.sleep(random.uniform(0.1, 0.5))  # Simulate work being done\n",
        "        with lock:  # Acquire the lock before modifying the list\n",
        "            if shared_list:\n",
        "                removed = shared_list.pop(0)  # Remove the first element\n",
        "                print(f\"Removed: {removed}. Current List: {shared_list}\")\n",
        "            else:\n",
        "                print(\"List is empty, nothing to remove.\")\n",
        "\n",
        "# Creating threads\n",
        "adder_thread = threading.Thread(target=add_numbers)\n",
        "remover_thread = threading.Thread(target=remove_numbers)\n",
        "\n",
        "# Starting threads\n",
        "adder_thread.start()\n",
        "remover_thread.start()\n",
        "\n",
        "# Waiting for both threads to finish\n",
        "adder_thread.join()\n",
        "remover_thread.join()\n",
        "\n",
        "print(\"Final List:\", shared_list)\n"
      ],
      "metadata": {
        "id": "sni-H-Hcol9o",
        "outputId": "28bbdcb3-a80f-4857-9273-7b574a4230f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added: 0. Current List: [0]\n",
            "Removed: 0. Current List: []\n",
            "Added: 1. Current List: [1]\n",
            "Removed: 1. Current List: []\n",
            "Added: 2. Current List: [2]\n",
            "Removed: 2. Current List: []\n",
            "Added: 3. Current List: [3]\n",
            "Removed: 3. Current List: []\n",
            "Added: 4. Current List: [4]\n",
            "Added: 5. Current List: [4, 5]\n",
            "Removed: 4. Current List: [5]\n",
            "Added: 6. Current List: [5, 6]\n",
            "Added: 7. Current List: [5, 6, 7]\n",
            "Removed: 5. Current List: [6, 7]\n",
            "Added: 8. Current List: [6, 7, 8]\n",
            "Removed: 6. Current List: [7, 8]\n",
            "Removed: 7. Current List: [8]\n",
            "Added: 9. Current List: [8, 9]\n",
            "Removed: 8. Current List: [9]\n",
            "Removed: 9. Current List: []\n",
            "Final List: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Describe the methods and tools available in Python for safely sharing data between threads and processes.**\n",
        "\n",
        "**1. Thread-Safe Data Sharing (within a single process)**\n",
        "\n",
        "Python’s Global Interpreter Lock (GIL) ensures that only one thread executes Python bytecode at a time, which prevents race conditions at a low level. However, for more complex scenarios, thread-safe mechanisms are necessary. Here are the common tools:\n",
        "\n",
        " **threading.Lock** (Mutual Exclusion Lock)\n",
        "\n",
        "A Lock is the simplest synchronization primitive. It ensures that only one thread accesses a shared resource at a time.\n",
        "\n",
        "The lock is acquired by one thread and released after the operation. Other threads wait until the lock is available.\n",
        "\n",
        "**2. Process-Safe Data Sharing (across multiple processes)**\n",
        "\n",
        "When working with multiple processes (via the multiprocessing module), memory space is not shared. Therefore, Python provides separate synchronization tools for inter-process communication (IPC)\n",
        "\n",
        "**a. multiprocessing.Queue**\n",
        "\n",
        "A Queue in the multiprocessing module provides a safe way to pass data between processes. It uses underlying OS mechanisms like pipes or sockets for communication.\n",
        "\n",
        "**b. multiprocessing.Pipe**\n",
        "\n",
        "Pipe allows duplex communication between two processes. It returns two connection objects, one for each end of the pipe. Processes can send and receive data through these objects.\n",
        "\n",
        "**c. multiprocessing.Value and multiprocessing.Array**\n",
        "\n",
        "These provide shared memory between processes for primitive data types and arrays, respectively. These objects can be protected with locks to ensure safe access.\n",
        "\n",
        "etc.."
      ],
      "metadata": {
        "id": "WqGOjl8IqkKu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Discuss why it’s crucial to handle exceptions in concurrent programs and the techniques available for doing so.**\n",
        "\n",
        "Handling exceptions in concurrent programs is crucial because multiple threads or processes operate simultaneously, which increases the complexity and potential for errors. If exceptions aren't managed properly, they can cause unexpected behavior, crashes, or inconsistent program states, especially when multiple resources or shared data are involved.\n",
        "\n",
        "**1. Prevention of Program Crashes**\n",
        "\n",
        "In a concurrent program, if an exception occurs in one thread or process and is not handled, it may lead to the termination of that thread or even the whole program, depending on how exceptions propagate. This can leave resources like files, network connections, or locks in an undefined state, leading to further errors or crashes.\n",
        "\n",
        "**2. Preserving Data Integrity**\n",
        "\n",
        "Many concurrent programs work with shared resources, such as memory, files, or databases. Unhandled exceptions can result in corrupted or inconsistent data if the program is interrupted while modifying these resources. For example, an exception during an update to a shared variable could lead to data being only partially updated, causing inconsistencies.\n",
        "\n",
        "**3. Ensuring Thread/Process Synchronization**\n",
        "\n",
        "Proper exception handling helps maintain synchronization between threads or processes. If an exception goes unhandled, a thread may release locks or semaphores improperly, potentially causing deadlocks or race conditions in other parts of the program.\n",
        "\n",
        "**4. Avoiding Resource Leaks**\n",
        "\n",
        "In concurrent programs, resource leaks (e.g., memory, file descriptors, network sockets) can be especially problematic because unhandled exceptions might leave resources unreleased, affecting the performance of other threads and processes.\n",
        "\n",
        "**5. Improved Debugging and Logging**\n",
        "\n",
        "Handling exceptions properly allows the program to log relevant information and continue running, making it easier to identify, debug, and fix issues, especially when running many threads or processes concurrently.\n",
        "\n",
        "\n",
        "**Techniques for Handling Exceptions in Concurrent Python Programs**\n",
        "\n",
        "**1. Using try-except Blocks**\n",
        "\n",
        "This is the simplest way to handle exceptions. In each thread or process, you can wrap code that might raise exceptions in try-except blocks, ensuring that any exception is caught and handled gracefully:"
      ],
      "metadata": {
        "id": "iVdPauWExRdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "def worker():\n",
        "    try:\n",
        "\n",
        "        result = 10 / 0  # Will raise an exception\n",
        "    except ZeroDivisionError as e:\n",
        "        print(f\"Exception handled in thread: {e}\")\n",
        "\n",
        "thread = threading.Thread(target=worker)\n",
        "thread.start()\n"
      ],
      "metadata": {
        "id": "9CVb_v-20cPh",
        "outputId": "fc102cc0-5375-42be-81fb-64980cbbc593",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception handled in thread: division by zero\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Exception Handling in concurrent.futures**\n",
        "\n",
        "The concurrent.futures module provides higher-level thread and process pools. It has built-in mechanisms to handle exceptions raised in concurrent tasks, allowing the main thread to manage exceptions from child threads or processes:"
      ],
      "metadata": {
        "id": "oLt8fihi0qOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "def worker():\n",
        "    return 10 / 0  # Will raise an exception\n",
        "\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    future = executor.submit(worker)\n",
        "    try:\n",
        "        result = future.result()  # Will raise exception here\n",
        "    except ZeroDivisionError as e:\n",
        "        print(f\"Handled exception from thread pool: {e}\")\n"
      ],
      "metadata": {
        "id": "ZVGC__Df0xL6",
        "outputId": "60f677c9-8974-4a7b-c7c9-06500a7fc0eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Handled exception from thread pool: division by zero\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Exception Handling with multiprocessing**\n",
        "\n",
        "In multi-process programs, exceptions need to be handled in each child process. The multiprocessing module provides support for catching exceptions in a similar way to concurrent.futures, but inter-process communication (IPC) mechanisms like Queue or Pipe are also commonly used:"
      ],
      "metadata": {
        "id": "PEdz0gvA283u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process, Queue\n",
        "\n",
        "def worker(q):\n",
        "    try:\n",
        "        result = 10 / 0\n",
        "    except Exception as e:\n",
        "        q.put(e)\n",
        "\n",
        "q = Queue()\n",
        "process = Process(target=worker, args=(q,))\n",
        "process.start()\n",
        "process.join()\n",
        "\n",
        "if not q.empty():\n",
        "    exception = q.get()\n",
        "    print(f\"Exception handled from process: {exception}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "XOu7B2sr3ClK",
        "outputId": "90673847-fe68-4cea-b30e-7050eef4f1dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception handled from process: division by zero\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently. Use concurrent.futures.ThreadPoolExecutor to manage the threads**"
      ],
      "metadata": {
        "id": "KLuxyIqC6ujn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import concurrent.futures\n",
        "\n",
        "\n",
        "# Function to calculate factorial of a number\n",
        "def factorial(n):\n",
        "    if n==0:\n",
        "        return 1\n",
        "    return n*factorial(n-1)\n",
        "\n",
        "# List of numbers for which we want to calculate factorials\n",
        "numbers = list(range(1, 11))\n",
        "\n",
        "# Using ThreadPoolExecutor to manage threads\n",
        "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "    # Submit tasks to thread pool and get results\n",
        "    results = executor.map(factorial, numbers)\n",
        "\n",
        "# Display the results\n",
        "for number, result in zip(numbers, results):\n",
        "    print(f\"Factorial of {number} is {result}\")\n"
      ],
      "metadata": {
        "id": "KzWuehNg6vDo",
        "outputId": "e8d25955-9e69-48ca-b9c1-8bbe16e2f7bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Factorial of 1 is 1\n",
            "Factorial of 2 is 2\n",
            "Factorial of 3 is 6\n",
            "Factorial of 4 is 24\n",
            "Factorial of 5 is 120\n",
            "Factorial of 6 is 720\n",
            "Factorial of 7 is 5040\n",
            "Factorial of 8 is 40320\n",
            "Factorial of 9 is 362880\n",
            "Factorial of 10 is 3628800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8 processes).**"
      ],
      "metadata": {
        "id": "4DDaUF2r7EIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "import time\n",
        "\n",
        "# Function to compute the square of a number\n",
        "def square(n):\n",
        "    return n * n\n",
        "\n",
        "# List of numbers for which we want to compute squares\n",
        "numbers = list(range(1, 11))\n",
        "\n",
        "# Function to compute squares using multiprocessing Pool and measure time\n",
        "def compute_squares(pool_size):\n",
        "    with multiprocessing.Pool(pool_size) as pool:\n",
        "        start_time = time.perf_counter()  # Start time\n",
        "        results = pool.map(square, numbers)  # Parallel computation\n",
        "        end_time = time.perf_counter()  # End time\n",
        "        return results, (end_time - start_time)\n",
        "\n",
        "# List of different pool sizes to test\n",
        "pool_sizes = [2, 4, 8]\n",
        "\n",
        "# Loop through each pool size, compute squares, and print time taken\n",
        "for pool_size in pool_sizes:\n",
        "    results, time_taken = compute_squares(pool_size)\n",
        "    print(f\"Pool size: {pool_size}\")\n",
        "    print(f\"Results: {results}\")\n",
        "    print(f\"Time taken: {time_taken:.6f} seconds\\n\")\n"
      ],
      "metadata": {
        "id": "OxIGY97T7Vr7",
        "outputId": "3b6cbc86-91b9-4d34-c33e-e2ff691b33a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pool size: 2\n",
            "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken: 0.002906 seconds\n",
            "\n",
            "Pool size: 4\n",
            "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken: 0.002878 seconds\n",
            "\n",
            "Pool size: 8\n",
            "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken: 0.003422 seconds\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
